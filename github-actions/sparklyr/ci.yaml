on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

name: CI

jobs:
  CI:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: 'Spark 2.2.1 (R oldrel, openjdk8)'
            r: 'oldrel'
            env:
              ARROW_ENABLED: 'false'
              SPARK_VERSION: '2.2.1'
              LIVY_VERSION: 'NONE'
              JAVA_VERSION: 'openjdk8'
          - name: 'Spark 2.3.2 (R release, openjdk8)'
            r: 'release'
            env:
              ARROW_ENABLED: 'false'
              SPARK_VERSION: '2.3.2'
              LIVY_VERSION: 'NONE'
              JAVA_VERSION: 'openjdk8'
          - name: 'Spark 2.4.4 (R release, openjdk8)'
            r: 'release'
            env:
              ARROW_ENABLED: 'false'
              SPARK_VERSION: '2.4.4'
              LIVY_VERSION: 'NONE'
              JAVA_VERSION: 'openjdk8'
          - name: 'Spark 2.4.4 (R release, openjdk8, CODE_COVERAGE=true)'
            r: 'release'
            env:
              ARROW_ENABLED: 'false'
              SPARK_VERSION: '2.4.4'
              LIVY_VERSION: 'NONE'
              JAVA_VERSION: 'openjdk8'
              CODE_COVERAGE: 'true'
          - name: 'Spark 3.0.0 (R release, openjdk8)'
            r: 'release'
            env:
              ARROW_ENABLED: 'false'
              SPARK_VERSION: '3.0.0'
              LIVY_VERSION: 'NONE'
              JAVA_VERSION: 'openjdk8'
          - name: 'Spark 3.0.0 (R release, openjdk8, dbplyr 1.4.4)'
            r: 'release'
            env:
              ARROW_ENABLED: 'false'
              SPARK_VERSION: '3.0.0'
              LIVY_VERSION: 'NONE'
              JAVA_VERSION: 'openjdk8'
              DBPLYR_VERSION: '1.4.4'
          - name: 'Spark 3.0.0 (R release, openjdk8, dbplyr API edition 1)'
            r: 'release'
            env:
              ARROW_ENABLED: 'false'
              SPARK_VERSION: '3.0.0'
              LIVY_VERSION: 'NONE'
              JAVA_VERSION: 'openjdk8'
              DBPLYR_API_EDITION: '1'
          - name: 'Spark 3.0.0 (R release, openjdk11)'
            r: 'release'
            env:
              ARROW_ENABLED: 'false'
              SPARK_VERSION: '3.0.0'
              LIVY_VERSION: 'NONE'
              JAVA_URL: 'https://github.com/AdoptOpenJDK/openjdk11-binaries/releases/download/jdk-11.0.1%2B13/OpenJDK11U-jdk_x64_linux_hotspot_11.0.1_13.tar.gz'
          - name: 'Livy 0.5.0 (R release, openjdk8, Spark 2.3.0)'
            r: 'release'
            env:
              ARROW_ENABLED: 'false'
              SPARK_VERSION: '2.3.0'
              LIVY_VERSION: '0.5.0'
              JAVA_VERSION: 'openjdk8'
              LIVY_TEST_CASES_SUBSET: '1'
          - name: 'Livy 0.5.0 (R release, openjdk8, Spark 2.3.0)'
            r: 'release'
            env:
              ARROW_ENABLED: 'false'
              SPARK_VERSION: '2.3.0'
              LIVY_VERSION: '0.5.0'
              JAVA_VERSION: 'openjdk8'
              LIVY_TEST_CASES_SUBSET: '2'
          - name: 'Livy 0.5.0 (R release, openjdk8, Spark 2.4.0)'
            r: 'release'
            env:
              ARROW_ENABLED: 'false'
              SPARK_VERSION: '2.4.0'
              LIVY_VERSION: '0.5.0'
              JAVA_VERSION: 'openjdk8'
              LIVY_TEST_CASES_SUBSET: '1'
          - name: 'Livy 0.5.0 (R release, openjdk8, Spark 2.4.0)'
            r: 'release'
            env:
              ARROW_ENABLED: 'false'
              SPARK_VERSION: '2.4.0'
              LIVY_VERSION: '0.5.0'
              JAVA_VERSION: 'openjdk8'
              LIVY_TEST_CASES_SUBSET: '2'
          - name: 'Arrow (release)'
            r: 'release'
            env:
              ARROW_ENABLED: 'true'
              SPARK_VERSION: '3.0.0'
              LIVY_VERSION: 'NONE'
              JAVA_VERSION: 'openjdk8'
          - name: 'Arrow (nightly)'
            r: 'release'
            env:
              ARROW_ENABLED: 'true'
              ARROW_VERSION: 'devel'
              SPARK_VERSION: '3.0.0'
              LIVY_VERSION: 'NONE'
              JAVA_VERSION: 'openjdk8'
          - name: 'Deps Devel (tidyverse, r-lib, forge)'
            r: 'release'
            env:
              ARROW_ENABLED: 'false'
              SPARK_VERSION: '3.0.0'
              LIVY_VERSION: 'NONE'
              R_DEVEL_PACKAGES: 'true'
              JAVA_VERSION: 'openjdk8'
    env:
      ${{ matrix.env }}
    steps:
      - name: Mount tmpfs
        run: sudo mount -t tmpfs tmpfs /tmp
      - name: Delete pre-existing R binaries
        run: |
          for b in R Rscript
          do
            while [ -n "$(which "$b")" ]
            do
              sudo rm -v "$(which "$b")"
            done
          done
        shell: bash
      - uses: actions/checkout@v2
      - uses: r-lib/actions/setup-r@master
        with:
          r-version: ${{ matrix.r }}
      - name: Install Java
        id: install-java
        run: |
          sudo apt-get -y remove --purge default-jdk adoptopenjdk-11-hotspot || :

          if [[ ! -z "$JAVA_URL" ]]; then
            wget https://github.com/sormuras/bach/raw/master/install-jdk.sh
            source ./install-jdk.sh --url $JAVA_URL
          else
            sudo apt-get -y install openjdk-8-jdk
            wget https://raw.githubusercontent.com/michaelklishin/jdk_switcher/master/jdk_switcher.sh
            . ./jdk_switcher.sh
            jdk_switcher use openjdk8;
          fi

          echo "${JAVA_HOME}"
          echo "::set-output name=JAVA_HOME::${JAVA_HOME}"
      - name: Install Spark master if necessary
        run: |
          if [[ $SPARK_VERSION == 'master' ]]; then
            source ./ci/spark-master-install.sh;
          fi
      - name: Cache R packages
        if: runner.os != 'Windows'
        uses: actions/cache@master
        with:
          path: ${{ env.R_LIBS_USER }}
          key: sparklyr-ci-${{ runner.os }}-R-${{ matrix.r }}-${{ env.ARROW_ENABLED }}-${{ hashFiles('DESCRIPTION') }}-${{ hashFiles('ci/install_r_dependencies.sh') }}
          restore-keys: sparklyr-ci-${{ runner.os }}-R-${{ matrix.r }}
      - name: Cache Spark & Livy installations
        if: runner.os != 'Windows'
        uses: actions/cache@master
        with:
          path: ~/spark
          key: sparklyr-apache-spark-${{ runner.os }}-${{ env.SPARK_VERSION }}-${{ env.LIVY_VERSION }}
          restore-keys: sparklyr-apache-spark-${{ runner.os }}-${{ env.SPARK_VERSION }}
      - name: Install system dependencies
        run: |
          sudo DEBIAN_FRONTEND=noninteractive apt-get -y install libcurl4-gnutls-dev libgit2-dev procps socat
      - name: Install dependencies
        run: source ./ci/install_r_dependencies.sh
        continue-on-error: true
      - name: Build
        env:
          WARNINGS_ARE_ERRORS: 1
        run: R CMD build .
      - name: Check
        env:
          _R_CHECK_FORCE_SUGGESTS_: false
          WARNINGS_ARE_ERRORS: 1
        run: R CMD check --no-build-vignettes --no-manual --no-tests sparklyr*tar.gz
      - name: Install sparklyr and other required package(s) from source
        run: Rscript ci/.ci.R --install_pkgs
      - name: Verify embedded R sources in sparklyr-*.jar
        run: Rscript ci/.ci.R --verify-embedded-srcs
      - name: Run tests
        run: |
          export SPARKLYR_LOG_FILE=/tmp/sparklyr.log
          export JAVA_HOME="${{ steps.install-java.outputs.JAVA_HOME }}"

          sudo timedatectl set-timezone America/Los_Angeles
          export TZ='America/Los_Angeles'

          if [[ $CODE_COVERAGE == "true" ]]; then
            Rscript ci/.ci.R --coverage || :
          else
            Rscript ci/.ci.R --testthat
          fi
      - uses: actions/upload-artifact@v1
        if: failure()
        with:
          name: Worker logs
          path: /tmp/sparklyr.log
      - name: Dump worker logs on failure
        if: failure()
        run: cat /tmp/sparklyr.log
